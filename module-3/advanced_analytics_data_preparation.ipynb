{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b7c093",
   "metadata": {},
   "source": [
    "# ML Workflow Intro\n",
    "\n",
    "![Image](./img/scikit_learn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9298e",
   "metadata": {},
   "source": [
    "## Installing scikit-learn\n",
    "\n",
    "```$ conda create -n sklearn-env -c conda-forge scikit-learn```\n",
    "\n",
    "```$ conda activate sklearn-env```\n",
    "\n",
    "```$ conda install ipykernel```\n",
    "\n",
    "```$ conda install pandas```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c611949c",
   "metadata": {},
   "source": [
    "## [API Reference](https://scikit-learn.org/stable/modules/classes.html#)\n",
    "\n",
    "- Datasets\n",
    "- Impute\n",
    "- Preprocessing and Normalization\n",
    "- Model Selection\n",
    "- Metrics\n",
    "- Linear Models\n",
    "- Ensemble Methods\n",
    "- Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d5977",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d781db1d",
   "metadata": {},
   "source": [
    "# ML Data Preparation\n",
    "\n",
    "- Missing values\n",
    "\n",
    "- Encoding\n",
    "\n",
    "- Scaling\n",
    "\n",
    "- Data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42371b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bde8ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70a156",
   "metadata": {},
   "source": [
    "## Missing values\n",
    "\n",
    "__scikit-learn__ estimators assume that all values in an array are numerical, and that all have and hold meaning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading a classic!!!\n",
    "\n",
    "titanic = pd.read_csv('./datasets/titanic.csv')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f533a9",
   "metadata": {},
   "source": [
    "__Dataset Features:__\n",
    "\n",
    "- PassengerId - Numerical PK ([1:891])\n",
    "\n",
    "- Survived - Survival (0 = No; 1 = Yes)\n",
    "\n",
    "- Pclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "\n",
    "- Name - Name of the passanger\n",
    "\n",
    "- Sex - Genre of the passanger\n",
    "\n",
    "- Age - Age of the passanger\n",
    "\n",
    "- SibSp - Number of Siblings/Spouses Aboard\n",
    "\n",
    "- Parch - Number of Parents/Children Aboard\n",
    "\n",
    "- Ticket - Ticket Number\n",
    "\n",
    "- Fare - Passenger Fare\n",
    "\n",
    "- Cabin - Cabin Number\n",
    "\n",
    "- Embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad3f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric features\n",
    "\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d72764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features\n",
    "\n",
    "cols = ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "\n",
    "cat_list = []\n",
    "for col in cols:\n",
    "    cat = titanic[col].unique()\n",
    "    cat_num = len(cat)\n",
    "    cat_dict = {\"categorical_variable\":col,\n",
    "                \"number_of_possible_values\":cat_num,\n",
    "                \"values\":cat}\n",
    "    cat_list.append(cat_dict)\n",
    "    \n",
    "categories = pd.DataFrame(cat_list).sort_values(by=\"number_of_possible_values\",\n",
    "                                                ascending=False).reset_index(drop=True)\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values percentage function\n",
    "\n",
    "def missing_percentage(df):\n",
    "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "    missing_values_df = pd.DataFrame({'column_name': df.columns,'percent_missing': percent_missing})\n",
    "    return missing_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values percentage\n",
    "\n",
    "missing_percentage(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32214496",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9cf830",
   "metadata": {},
   "source": [
    "### Delete missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "no_nan_col = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Fare']\n",
    "titanic_no_nan_col = titanic[no_nan_col]\n",
    "titanic_no_nan_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e46bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage(titanic_no_nan_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d591c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows\n",
    "\n",
    "titanic_no_nan_rows = titanic.dropna()\n",
    "titanic_no_nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7875e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage(titanic_no_nan_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244b117",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317a616",
   "metadata": {},
   "source": [
    "### Imputation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make a copy\n",
    "\n",
    "titanic_input = titanic.copy()\n",
    "titanic_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe8e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas -> Numeric continuous values\n",
    "\n",
    "titanic_input['Age'] = titanic_input['Age'].fillna(titanic_input['Age'].mean())\n",
    "#titanic_input['Age'] = titanic_input['Age'].replace(np.nan, titanic_input['Age'].mean())\n",
    "missing_percentage(titanic_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas -> Categorical values\n",
    "\n",
    "titanic_input['Embarked'] = titanic_input['Embarked'].fillna(titanic_input['Embarked'].value_counts().index[0])\n",
    "missing_percentage(titanic_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6626c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make another copy\n",
    "\n",
    "titanic_input = titanic.copy()\n",
    "titanic_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697cd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn univariate feature imputation -> Numeric continuous values\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean', missing_values=np.nan)\n",
    "type(imputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18066779",
   "metadata": {},
   "source": [
    "#### [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "\n",
    "![Image](./img/imputer_methods.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d67f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = imputer.fit(titanic_input[['Age']])\n",
    "imputer.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_input['Age'] = imputer.transform(titanic_input[['Age']])\n",
    "missing_percentage(titanic_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9046388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn univariate feature imputation -> Categorical values\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent', missing_values=np.nan)\n",
    "imputer = imputer.fit(titanic_input[['Embarked']])\n",
    "titanic_input['Embarked'] = imputer.transform(titanic_input[['Embarked']])\n",
    "missing_percentage(titanic_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca7828",
   "metadata": {},
   "source": [
    "#### Other options:\n",
    "\n",
    "- Last observation carried forward method: `.fillna(method='ffill')`)\n",
    "- Iterpolation of the variable before and after a timestamp: `.interpolate(method='linear', limit_direction='forward', axis=0)`\n",
    "- Using Algorithms that support missing values (no available for Sklearn algorithms)\n",
    "- Missing values prediction (Machine Learning for Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612427c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648a86e",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data\n",
    "\n",
    "again, __scikit-learn__ estimators assume that all values in an array are numerical, and that all have and hold meaning!\n",
    "\n",
    "__Very Important:__ Ordinal Data vs. Nominal Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we get the categorical data\n",
    "cat_cols = ['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "titanic_enconded = titanic[cat_cols]\n",
    "titanic_enconded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23446d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list = []\n",
    "for col in cat_cols:\n",
    "    cat = titanic[col].unique()\n",
    "    cat_num = len(cat)\n",
    "    cat_dict = {\"categorical_variable\":col,\n",
    "                \"number_of_possible_values\":cat_num,\n",
    "                \"values\":cat}\n",
    "    cat_list.append(cat_dict)\n",
    "    \n",
    "cat_df = pd.DataFrame(cat_list).sort_values(by=\"number_of_possible_values\",\n",
    "                                                ascending=False).reset_index(drop=True)\n",
    "cat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0b426",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da6a7e4",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc919fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {'S':1, 'C':2, 'Q':3}\n",
    "def ordinal_encoding(x):\n",
    "    for key in encoding:\n",
    "        if x == key:\n",
    "            return encoding[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_enconded['Embarked_num'] = titanic_enconded['Embarked'].apply(ordinal_encoding)\n",
    "titanic_enconded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87988489",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9bc9d4",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba39ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
    "\n",
    "cat_cols = ['Name', 'Pclass', 'Sex', 'Embarked']\n",
    "titanic_one_hot_encoding = pd.get_dummies(titanic[cat_cols], \n",
    "                                          columns=['Sex', 'Pclass'], \n",
    "                                          drop_first=True)\n",
    "titanic_one_hot_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a83004",
   "metadata": {},
   "source": [
    "__You can also use the [skalearn method](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) for it__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0f245",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e594ab",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Scaling of a dataset is a common requirement for many machine learning estimators. Typically this is done by removing the mean and scaling to unit variance.\n",
    "\n",
    "__Why is it important?__ If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "\n",
    "![Image](./img/scaling.jpg)\n",
    "\n",
    "[Here](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html) you may find a comparison between different approches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "\n",
    "sample_data = titanic[['Age', 'Pclass']]\n",
    "sample_data.describe()\n",
    "#sample_data = sample_data.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6c538",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027ad12",
   "metadata": {},
   "source": [
    "### [Standarization](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "\n",
    "The result of standardization (or Z-score normalization) is that the features will be rescaled so that they’ll have the properties of a standard normal distribution with μ=0  and σ=1 where μ is the mean (average) and σ is the standard deviation from the mean; standard scores (also called z scores) of the samples are calculated as follows:\n",
    "\n",
    "![Image](./img/standarization.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scikit-learn .StandardScaler()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(sample_data)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(scaled_data, columns=['Age', 'Pclass'])\n",
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7362ed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b1132",
   "metadata": {},
   "source": [
    "### [MinMax Scaling or Normalization](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "\n",
    "In this approach, the data is scaled to a fixed range - usually 0 to 1. The cost of having this bounded range - in contrast to standardization - is that we will end up with smaller standard deviations, which can suppress the effect of outliers. A Min-Max scaling is typically done via the following equation:\n",
    "\n",
    "![Image](./img/normalization.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea35891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scikit-learn .MinMaxScaler()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(sample_data)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2287ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(scaled_data, columns=['Age', 'Pclass'])\n",
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ffad88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b5780",
   "metadata": {},
   "source": [
    "### [Robust Scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)\n",
    "\n",
    "This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).\n",
    "\n",
    "Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Median and interquartile range are then stored to be used on later data using the transform method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a072a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scikit-learn .MinMaxScaler()\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(sample_data)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eda4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(scaled_data, columns=['Age', 'Pclass'])\n",
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e98191",
   "metadata": {},
   "source": [
    "[Here](https://sebastianraschka.com/Articles/2014_about_feature_scaling.html) you may find more info about scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07c1c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd50a6",
   "metadata": {},
   "source": [
    "## Data imbalance (mainly classification)\n",
    "\n",
    "- Get more data\n",
    "\n",
    "- Resampling: Under-sampling and Over-sampling\n",
    "\n",
    "[Imbalanced-learn](https://imbalanced-learn.org/stable/references/index.html) is an open source, MIT-licensed library relying on scikit-learn that provides tools when dealing with classification with imbalanced classes.\n",
    "\n",
    "`conda install -c conda-forge imbalanced-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling example: original data\n",
    "\n",
    "X, y = make_classification(n_classes=2, \n",
    "                           class_sep=2, \n",
    "                           weights=[0.1, 0.9], \n",
    "                           n_informative=3, \n",
    "                           n_redundant=1, \n",
    "                           flip_y=0, \n",
    "                           n_features=20, \n",
    "                           n_clusters_per_class=1, \n",
    "                           n_samples=1000, \n",
    "                           random_state=42)\n",
    "\n",
    "print(X.shape, y.shape, Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "print(X_res.shape, y_res.shape, Counter(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33623753",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-sklearn-env]",
   "language": "python",
   "name": "conda-env-.conda-sklearn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
