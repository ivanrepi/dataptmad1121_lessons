{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd07e5c",
   "metadata": {},
   "source": [
    "# ML Workflow - Feature Selection & Engineering\n",
    "\n",
    "![Image](./img/scikit_learn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f95c6de",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "- Improve the accuracy with which the model is able to predict for new data.\n",
    "\n",
    "- Reduce computational cost.\n",
    "\n",
    "- Produce a more interpretable model.\n",
    "\n",
    "![Image](./img/feature_selection.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae027f43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462c508",
   "metadata": {},
   "source": [
    "### Manual feature selection\n",
    "\n",
    "- data analysis\n",
    "- intuition\n",
    "- domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2edb449",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Diabetes dataset\n",
    "\n",
    "diabetes = datasets.load_diabetes(as_frame=True)\n",
    "description = diabetes.DESCR\n",
    "\n",
    "diabetes = diabetes['data'].merge(diabetes['target'], left_index=True, right_index=True)\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153422da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc59809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicles dataset\n",
    "\n",
    "vehicles = pd.read_csv('./datasets/vehicles.csv')\n",
    "vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c05da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8176d45",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1008f9c",
   "metadata": {},
   "source": [
    "### Manual feature selection - [Correlation](https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/a-comparison-of-the-pearson-and-spearman-correlation-methods/)\n",
    "\n",
    "A correlation coefficient measures the extent to which two variables tend to change together. The coefficient describes both the strength and the direction of the relationship.\n",
    "\n",
    "__Pearson:__ The Pearson correlation evaluates the linear relationship between two continuous variables. A relationship is linear when a change in one variable is associated with a proportional change in the other variable.\n",
    "\n",
    "__Spearman:__ The Spearman correlation evaluates the monotonic relationship between two continuous or ordinal variables. In a monotonic relationship, the variables tend to change together, but not necessarily at a constant rate.\n",
    "\n",
    "We will use [`pandas.Series.corr`](https://pandas.pydata.org/docs/reference/api/pandas.Series.corr.html) and [`pandas.DataFrame.corr`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(14,7))\n",
    "axs[0].scatter(diabetes['s1'], diabetes['s2'], c='green')\n",
    "axs[0].set(xlabel='s1', ylabel='s2', title='Diabetes')\n",
    "axs[1].scatter(vehicles['City MPG'], vehicles['Highway MPG'])\n",
    "axs[1].set(xlabel='City MPG', ylabel='Highway MPG', title='Vehicles');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e3b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson\n",
    "\n",
    "print(vehicles['City MPG'].corr(vehicles['Highway MPG'], method='pearson'))\n",
    "print(diabetes['s1'].corr(diabetes['s2'], method='pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4260b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman\n",
    "\n",
    "print(vehicles['City MPG'].corr(vehicles['Highway MPG'], method='spearman'))\n",
    "print(diabetes['s1'].corr(diabetes['s2'], method='spearman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eeffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_correlation = diabetes.corr()\n",
    "diabetes_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "sns.heatmap(diabetes.corr(method='pearson'), annot=True, fmt='.2f', ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56202c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_correlation = vehicles.corr()\n",
    "vehicles_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b97d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "sns.heatmap(vehicles.corr(method='pearson'), annot=True, fmt='.2f', ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da3960b",
   "metadata": {},
   "source": [
    "__We may want to remove a feature from the training phase because:__\n",
    "\n",
    "- A feature that is highly correlated with another feature in the data set. If this is the case then both features are in essence providing the same information. Some algorithms are sensitive to correlated features.\n",
    "\n",
    "- Features that provide little to no information. An example would be a feature where most examples have the same value.\n",
    "\n",
    "- Features that have little to no statistical relationship with the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8561be11",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9caaa4",
   "metadata": {},
   "source": [
    "### Automated feature selection - [Variance threshold](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html)\n",
    "\n",
    "This method takes a threshold value and when fitted to a feature set will remove any features below this threshold. The default value for the threshold is 0 and this will remove any features with zero variance, or in other words where all values are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b775e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes dataset\n",
    "\n",
    "X = diabetes.drop('target', axis=1)\n",
    "y = diabetes['target']\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.0)\n",
    "print(\"Original feature shape:\", X.shape)\n",
    "\n",
    "new_X = selector.fit_transform(X)\n",
    "print(\"Transformed feature shape:\", new_X.shape)\n",
    "\n",
    "# Selected features\n",
    "print(\"Selected features:\", selector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicles dataset\n",
    "\n",
    "X = vehicles[['Engine Displacement', \n",
    "              'Cylinders', \n",
    "              'Fuel Barrels/Year', \n",
    "              'City MPG', \n",
    "              'Highway MPG', \n",
    "              'Combined MPG', \n",
    "              'CO2 Emission Grams/Mile']]\n",
    "y = vehicles['Fuel Cost/Year']\n",
    "\n",
    "selector = VarianceThreshold(threshold=5)\n",
    "print(\"Original feature shape:\", X.shape)\n",
    "\n",
    "new_X = selector.fit_transform(X)\n",
    "print(\"Transformed feature shape:\", new_X.shape)\n",
    "\n",
    "# Selected features\n",
    "print(\"Selected features:\", selector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc056f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breast cancer dataset\n",
    "\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X = breast_cancer['data']\n",
    "y = breast_cancer['target']\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.5)\n",
    "print(\"Original feature shape:\", X.shape)\n",
    "\n",
    "new_X = selector.fit_transform(X)\n",
    "print(\"Transformed feature shape:\", new_X.shape)\n",
    "\n",
    "# Selected features\n",
    "print(\"Selected features:\", selector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d554053",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a9cc7",
   "metadata": {},
   "source": [
    "### Automated feature selection - [Univariate feature selection](https://statistics.laerd.com/statistical-guides/one-way-anova-statistical-guide.php)\n",
    "\n",
    "The one-way ANOVA compares the means between the groups you are interested in and determines whether any of those means are statistically significantly different from each other. Specifically, it tests the null hypothesis:\n",
    "\n",
    "![Image](./img/anova.JPG)\n",
    "\n",
    "where µ = group mean and k = number of groups. If, however, the one-way ANOVA returns a statistically significant result, we accept the alternative hypothesis (HA), which is that there are at least two group means that are statistically significantly different from each other.\n",
    "\n",
    "[Here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) you may find the scikit-learn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d67225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes dataset\n",
    "\n",
    "X = diabetes.drop('target', axis=1)\n",
    "y = diabetes['target']\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k='all')\n",
    "print(\"Original feature shape:\", X.shape)\n",
    "\n",
    "new_X = selector.fit_transform(X, y)\n",
    "print(\"Transformed feature shape:\", new_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1cbb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicles dataset\n",
    "\n",
    "X = vehicles[['Engine Displacement', \n",
    "              'Cylinders', \n",
    "              'Fuel Barrels/Year', \n",
    "              'City MPG', \n",
    "              'Highway MPG', \n",
    "              'Combined MPG', \n",
    "              'CO2 Emission Grams/Mile']]\n",
    "y = vehicles['Fuel Cost/Year']\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k='all')\n",
    "print(\"Original feature shape:\", X.shape)\n",
    "\n",
    "new_X = selector.fit_transform(X, y)\n",
    "print(\"Transformed feature shape:\", new_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breast cancer dataset\n",
    "\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X = breast_cancer['data']\n",
    "y = breast_cancer['target']\n",
    "\n",
    "selector = SelectKBest()\n",
    "print(\"Original feature shape:\", X.shape)\n",
    "\n",
    "new_X = selector.fit_transform(X, y)\n",
    "print(\"Transformed feature shape:\", new_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1955d097",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c375442",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "- Manual\n",
    "\n",
    "- Automated (e.g.: [Featuretools](https://www.featuretools.com/))\n",
    "\n",
    "![Image](./img/feature_engineering.jpg)\n",
    "\n",
    "There are two main reasons:\n",
    "\n",
    "- __The information contained within the feature is stronger if the data is aggregated or represented in a different way__. An example here might be a feature containing the age of a person, aggregating the ages into buckets or bins may better represent the relationship to the target.\n",
    "\n",
    "- __A feature on its own does not have a strong enough statistical relationship with the target but when combined with another feature has a meaningful relationship__. Let’s say we have a data set that has a number of features based on credit history for a group of customers and a target that denotes if they have defaulted on a loan. Suppose we have a loan amount and a salary value. If we combined these into a new feature called “loan to salary ratio” this may give more or better information than those features alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bacca5",
   "metadata": {},
   "source": [
    "### Manual feature engineering\n",
    "\n",
    "- Binning\n",
    "\n",
    "- Extracting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7839ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical binning\n",
    "\n",
    "vehicles['num_bin'] = pd.cut(vehicles['Fuel Cost/Year'], bins=3, labels=[\"Low\", \"Mid\", \"High\"])\n",
    "vehicles['num_bin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbbff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical binning\n",
    "\n",
    "vehicles['Drivetrain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e2258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_bin(x):\n",
    "    if '4' in x:\n",
    "        return '4x4'\n",
    "    else:\n",
    "        return '4x2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles['cat_bin'] = vehicles['Drivetrain'].apply(cat_bin)\n",
    "vehicles['cat_bin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a0a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting date\n",
    "\n",
    "data = pd.DataFrame({'date':['01-01-2022',\n",
    "                             '10-01-2019',\n",
    "                             '13-08-2002',\n",
    "                             '28-09-1995',\n",
    "                             '13-01-1981']})\n",
    "\n",
    "data['date'] = pd.to_datetime(data.date, format=\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Year\n",
    "data['year'] = data['date'].dt.year\n",
    "\n",
    "#Extracting Month\n",
    "data['month'] = data['date'].dt.month\n",
    "\n",
    "#Extracting passed years since the date\n",
    "data['passed_years'] = date.today().year - data['date'].dt.year\n",
    "\n",
    "#Extracting passed months since the date\n",
    "data['passed_months'] = (date.today().year - data['date'].dt.year) * 12 + date.today().month - data['date'].dt.month\n",
    "\n",
    "#Extracting the weekday name of the date\n",
    "data['day_name'] = data['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc7632",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-sklearn-env]",
   "language": "python",
   "name": "conda-env-.conda-sklearn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
